{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from scipy.signal import savgol_filter\n",
    "import statsmodels.api as sm\n",
    "import pymc3 as pm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant\n",
    "from itertools import combinations\n",
    "# settings for seaborn plotting style\n",
    "sns.set(color_codes=True)\n",
    "# settings for seaborn plot sizes\n",
    "sns.set(rc={'figure.figsize':(12,6)})\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# import logistic regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# set seed for reproducibility\n",
    "np.random.seed(621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_pickle('nfl_df_averages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X that is df columns with 'Avg' in them\n",
    "X = df[[col for col in df.columns if 'Avg' in col]]\n",
    "# remove home_homeAvg and home_awayAvg\n",
    "X = X.drop(['home_homeAvg', 'home_awayAvg'], axis=1)\n",
    "\n",
    "y = df['winner']\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in df_full and a number, n of features, fits a random forest model, and returns the top n features\n",
    "def top_features(n, X_test=X_test, y_test=y_test, X_train=X_train, y_train=y_train):\n",
    "    np.random.seed(621)\n",
    "    # create a random forest model using the features list as the X and \"winner\" as the Y using sklearn\n",
    "    rfmodel = RandomForestClassifier(n_estimators=100)\n",
    "    rfmodel.fit(X_train, y_train)\n",
    "    # make predictions\n",
    "    predictions = rfmodel.predict(X_test)\n",
    "    # evaluate the model\n",
    "    #print(confusion_matrix(y_test, predictions))\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    # create a dataframe of the features and their importance\n",
    "    feature_importance = pd.DataFrame(rfmodel.feature_importances_, index=X_train.columns, columns=['importance'])\n",
    "    # sort the dataframe by importance\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    # return the top n features\n",
    "    # create a list of the top n features\n",
    "    top_features = feature_importance.head(n).index\n",
    "    # using only the top_features, create a new X_train and X_test\n",
    "    X_train = X_train[top_features]\n",
    "    X_test = X_test[top_features]\n",
    "    # create a new logistic regression model with max_iter = 10000000, L2 penalty, and C = 1, and sag solver\n",
    "    max_iter = 10000000\n",
    "    penalty = 'l2'\n",
    "    C = 1\n",
    "    solver = 'sag'\n",
    "    logmodel = LogisticRegression(max_iter=max_iter, penalty=penalty, C=C, solver=solver)\n",
    "    logmodel.fit(X_train, y_train)\n",
    "    # make predictions\n",
    "    predictions = logmodel.predict(X_test)\n",
    "    # evaluate the model\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    return feature_importance.head(n), accuracy_score(y_test, predictions), logmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455223880597015\n",
      "[[219 229]\n",
      " [153 471]]\n",
      "0.6436567164179104\n"
     ]
    }
   ],
   "source": [
    "logmodel = top_features(3)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 300\n",
      "Best max_depth: 15\n",
      "Best min_samples_leaf: 3\n",
      "Best Model Train Accuracy: 0.9983663943990665\n"
     ]
    }
   ],
   "source": [
    "# perform hyperparameter tuning on n_estimators, max_depth, and min_samples_leaf\n",
    "# create a list of values for n_estimators\n",
    "estimators = [100, 200, 300]\n",
    "\n",
    "# create a list of values for max_depth\n",
    "depth = [5, 10, 15]\n",
    "\n",
    "# create a list of values for min_samples_leaf\n",
    "leaf = [1, 2, 3]\n",
    "\n",
    "# create a list of hyperparameter options\n",
    "hyperparameters = dict(n_estimators=estimators, max_depth=depth, min_samples_leaf=leaf)\n",
    "\n",
    "# create a random forest classifier\n",
    "rf = RandomForestClassifier(random_state=621)\n",
    "\n",
    "# use GridSearch to search for the best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(rf, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# fit the model to the training data\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])\n",
    "\n",
    "# report bestmodel results\n",
    "print('Best Model Train Accuracy:', best_model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201 247]\n",
      " [153 471]]\n",
      "0.6268656716417911\n"
     ]
    }
   ],
   "source": [
    "# create a model using the best hyperparameters\n",
    "rf = RandomForestClassifier(n_estimators=best_model.best_estimator_.get_params()['n_estimators'], max_depth=best_model.best_estimator_.get_params()['max_depth'], min_samples_leaf=best_model.best_estimator_.get_params()['min_samples_leaf'], random_state=621)\n",
    "\n",
    "# fit the model to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.9s\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.2s\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.4s\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.3s\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.560 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.575 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.557 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.592 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.558 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.595 total time=   3.3s\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.5s\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.6s\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.8s\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.560 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.569 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.562 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.578 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.569 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.575 total time=   4.5s\n",
      "[CV 1/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.2s\n",
      "[CV 2/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.2s\n",
      "[CV 3/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.2s\n",
      "[CV 4/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.1s\n",
      "[CV 5/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.560 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.611 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.618 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.617 total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.630 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.610 total time=   3.1s\n",
      "[CV 1/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.4s\n",
      "[CV 2/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.4s\n",
      "[CV 3/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.559 total time=   1.4s\n",
      "[CV 5/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.625 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.621 total time=   5.1s\n",
      "[CV 3/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.629 total time=   2.9s\n",
      "[CV 4/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.644 total time=   2.1s\n",
      "[CV 5/5] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.624 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.629 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.613 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.621 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.638 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.630 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.593 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.561 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.565 total time=   4.0s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.576 total time=   3.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.586 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.599 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.620 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.604 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.624 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.625 total time=   4.2s\n",
      "[CV 1/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.551 total time=   2.4s\n",
      "[CV 2/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.594 total time=   3.2s\n",
      "[CV 3/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.568 total time=   3.7s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.585 total time=   2.8s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.576 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.609 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.629 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.637 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.627 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=sgd;, score=0.650 total time=   3.2s\n",
      "[CV 1/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.571 total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.585 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.573 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.557 total time=   3.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(30, 30, 30), learning_rate=adaptive, solver=adam;, score=0.590 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.622 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.617 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.625 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.627 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=sgd;, score=0.620 total time=   4.7s\n",
      "[CV 1/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.559 total time=   3.9s\n",
      "[CV 2/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.575 total time=   4.0s\n",
      "[CV 3/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.572 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.540 total time=   4.7s\n",
      "[CV 5/5] END activation=relu, alpha=0.05, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, solver=adam;, score=0.569 total time=   3.7s\n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (30, 30, 30), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(30, 30, 30),\n",
      "              learning_rate='adaptive', solver='sgd')\n",
      "0.6303383897316219\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaskyle/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# perform a grid search to find the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the parameter values that should be searched\n",
    "param_grid = {'hidden_layer_sizes': [(30,30,30), (50,50,50)],\n",
    "                'activation': ['logistic', 'relu'],\n",
    "                'solver': ['sgd', 'adam'],\n",
    "                'alpha': [0.0001, 0.05],\n",
    "                'learning_rate': ['adaptive']}\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(MLPClassifier(), param_grid, refit=True, verbose=3)\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# view the results as a pandas DataFrame\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# print the best parameters\n",
    "print(grid.best_params_)\n",
    "# print the best estimator\n",
    "print(grid.best_estimator_)\n",
    "# print the best score\n",
    "print(grid.best_score_)\n",
    "# print the best index\n",
    "print(grid.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Accuracy: 0.5690298507462687\n"
     ]
    }
   ],
   "source": [
    "# use grid.best_params_ to create a new model\n",
    "params = grid.best_params_\n",
    "mlp = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'], activation=params['activation'], solver=params['solver'], alpha=params['alpha'], learning_rate=params['learning_rate'], max_iter=1000000)\n",
    "\n",
    "# fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# predict using the best model\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# report bestmodel results\n",
    "print('Best Model Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.559 total time=   1.6s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.623 total time=   1.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.645 total time=   1.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.616 total time=   1.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.623 total time=   1.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.610 total time=   1.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.606 total time=   1.3s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.595 total time=   1.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.571 total time=   1.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.592 total time=   1.3s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.585 total time=   1.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.559 total time=   1.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.559 total time=   1.4s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.559 total time=   1.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.559 total time=   1.3s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.560 total time=   1.3s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.571 total time=   1.5s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.568 total time=   1.5s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.565 total time=   1.5s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.610 total time=   1.2s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.630 total time=   1.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.627 total time=   1.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.632 total time=   1.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.634 total time=   1.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.631 total time=   1.2s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.642 total time=   1.2s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.632 total time=   1.2s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.629 total time=   1.2s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.632 total time=   1.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.614 total time=   1.3s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.602 total time=   1.3s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.579 total time=   1.3s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.610 total time=   1.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.595 total time=   1.3s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.592 total time=   1.5s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.573 total time=   1.5s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.574 total time=   1.5s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.576 total time=   1.5s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.575 total time=   1.5s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.617 total time=   1.5s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.596 total time=   1.5s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.573 total time=   1.5s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.613 total time=   1.5s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.615 total time=   1.2s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.625 total time=   1.2s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.618 total time=   1.2s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.637 total time=   1.2s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.634 total time=   1.2s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.642 total time=   1.2s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.648 total time=   1.2s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.632 total time=   1.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.631 total time=   1.2s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.623 total time=   1.2s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.559 total time=   1.6s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.560 total time=   1.5s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.592 total time=   1.5s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.573 total time=   1.5s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.574 total time=   1.5s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.576 total time=   1.5s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.575 total time=   1.5s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.551 total time=   1.8s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.592 total time=   1.8s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.576 total time=   1.8s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.582 total time=   1.8s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.601 total time=   1.8s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.614 total time=   1.4s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.601 total time=   1.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.600 total time=   1.4s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.610 total time=   1.4s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.637 total time=   1.4s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.622 total time=   1.2s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.635 total time=   1.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.627 total time=   1.2s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.644 total time=   1.2s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.638 total time=   1.2s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.559 total time=   1.5s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.560 total time=   1.6s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.592 total time=   1.5s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.573 total time=   1.5s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.574 total time=   1.5s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.576 total time=   1.5s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.575 total time=   1.5s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.551 total time=   1.8s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.592 total time=   1.8s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.576 total time=   1.8s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.582 total time=   1.8s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.601 total time=   1.8s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.567 total time=   3.7s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.604 total time=   3.8s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.600 total time=   3.8s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.564 total time=   3.8s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.617 total time=   3.7s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.608 total time=   1.4s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.617 total time=   1.4s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.621 total time=   1.4s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.634 total time=   1.4s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.629 total time=   1.4s\n",
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.6473880597014925\n"
     ]
    }
   ],
   "source": [
    "# do a grid search to find the best parameters of the SVM model\n",
    "# import the SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters\n",
    "print(grid.best_params_)\n",
    "\n",
    "# report classification accuracy of the best model\n",
    "print(grid.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[229 219]\n",
      " [156 468]]\n",
      "0.6501865671641791\n"
     ]
    }
   ],
   "source": [
    "# create an SVM model\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1, random_state=621)\n",
    "\n",
    "# fit the model to the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6296641791044776\n"
     ]
    }
   ],
   "source": [
    "# create a Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "# fit the model\n",
    "gnb.fit(X_train, y_train)\n",
    "# predict on the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "# calculate the accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble (Logistic, rf, SVM, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226 222]\n",
      " [157 467]]\n",
      "0.6464552238805971\n"
     ]
    }
   ],
   "source": [
    "# create an ensemble model using mlp, logmodel, best_model, and svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('mlp', mlp), ('logmodel', logmodel), ('svm', svm)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "predictions = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[215 233]\n",
      " [146 478]]\n",
      "0.6464552238805971\n"
     ]
    }
   ],
   "source": [
    "# create an ensemble model using mlp, logmodel, best_model, and svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('mlp', mlp), ('rf', rf), ('svm', svm)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "predictions = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226 222]\n",
      " [154 470]]\n",
      "0.6492537313432836\n"
     ]
    }
   ],
   "source": [
    "# create an ensemble model using mlp, logmodel, best_model, and svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('logmodel', logmodel), ('rf', rf), ('svm', svm)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "predictions = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[288 160]\n",
      " [236 388]]\n",
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# create an ensemble model using gnb, logmodel, best_model, and svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('gnb', gnb),('logmodel', logmodel)], voting='hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "predictions = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1cb11db1d9dd19842c8062a0085b340bbaaa5168fc68161d11dbb0d0c58245c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
